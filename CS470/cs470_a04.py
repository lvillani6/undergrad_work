# -*- coding: utf-8 -*-
"""CS470_A04

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1O9Ktcs2vwsi4s667qSKBnt99QeGIO6xr
"""

import numpy as np
from matplotlib import pyplot as plt
import tensorflow as tf
from tensorflow.keras import datasets, layers, models

#a.1
(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()
class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']

print("Shape of the training dataset, number of images and resolution:", train_images.shape)
print("Shape of the testing dataset, number of images and resolution:", test_images.shape)
print("All distinct training labels:", np.unique(train_labels))

train_images = train_images/255.0
test_images = test_images/255.0



plt.figure(figsize=(10,10))
for i in range(25):
  plt.subplot(5,5,i+1)
  plt.xticks([])
  plt.yticks([])
  plt.grid(False)
  plt.imshow(train_images[i], cmap=plt.cm.binary)
  plt.xlabel(class_names[train_labels[i][0]])
plt.show()

#a.2

def cnn_model():
  model = models.Sequential()
  model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))
  model.add(layers.MaxPooling2D((2, 2)))
  model.add(layers.Conv2D(64, (3, 3), activation='relu'))
  model.add(layers.MaxPooling2D((2, 2)))
  model.add(layers.Conv2D(64, (3, 3), activation='relu'))
  model.add(layers.Flatten())
  model.add(layers.Dense(64, activation='relu'))
  model.add(layers.Dense(10))
  return model

model = cnn_model()
model.summary()

model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

#a.3
CNN_trained = model.fit(train_images, train_labels, epochs=10,
                        validation_data=(test_images, test_labels))

#a.4
print()
test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)
print('Test accuracy:', test_acc)
print()

print('='*50) #=================================================================

import random
from scipy import ndarray
import skimage as sk
from skimage import transform
from skimage import util

#b.1
#augmentation methods chosen are:
# horizontal flip
# random rotation

n_images = train_images.shape[0]

def random_rotation(image_array: ndarray):
    random_degree = random.uniform(-25, 25)     #random rotation between -25% to 25%
    return sk.transform.rotate(image_array, random_degree)

def horizontal_flip(image_array: ndarray):
    return image_array[:, ::-1]

hflip_train_images    = []
randrot_train_images  = []
for i in range(n_images):
  hflip_train_images.append(horizontal_flip(train_images[i]))
  randrot_train_images.append(random_rotation(train_images[i]))

augmented_train_images = []
augmented_train_images = np.concatenate((train_images,hflip_train_images,randrot_train_images))
augmented_train_labels = np.concatenate((train_labels, train_labels, train_labels))

plt.figure(figsize=(10,10))
for i in range(3):
  plt.subplot(1,3,i+1)
  plt.xticks([])
  plt.yticks([])
  plt.grid(False)
  plt.imshow(augmented_train_images[n_images*i], cmap=plt.cm.binary)
  plt.xlabel(class_names[augmented_train_labels[n_images*i][0]])
plt.show()

print('='*50)

#b.2
augmented_model = cnn_model()

augmented_model.summary()

augmented_model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

CNN_trained_aug = augmented_model.fit(augmented_train_images, augmented_train_labels, epochs=10,
                                  validation_data=(test_images, test_labels))

print()
aug_test_loss, aug_test_acc = augmented_model.evaluate(test_images,  test_labels, verbose=2)
print('Test accuracy:', aug_test_acc)
print()

print('='*50) #=================================================================